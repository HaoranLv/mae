{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e8052d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: annoy in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (1.17.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p37/lib/python3.7/site-packages (4.62.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p37/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "2.77.1\n"
     ]
    }
   ],
   "source": [
    "!pip install annoy tqdm # -i https://opentuna.cn/pypi/web/simple\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import pickle\n",
    "from annoy import AnnoyIndex\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "import tqdm\n",
    "import sagemaker\n",
    "print(sagemaker.__version__)\n",
    "\n",
    "from sagemaker.pytorch import PyTorch, PyTorchPredictor\n",
    "from sagemaker.pytorch.model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69974db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_mae(model_name, seq_net):\n",
    "    ann_filename = 'index_advance_'+model_name+'.ann'\n",
    "    keys_filename = 'keys_'+model_name+'.pkl'\n",
    "    if os.path.exists(ann_filename) and os.path.exists(keys_filename):\n",
    "        try:\n",
    "            f = 768  # TODO may change\n",
    "            u = AnnoyIndex(f, 'euclidean')\n",
    "            u.load(ann_filename)\n",
    "        except:\n",
    "            f = 2048  # TODO may change\n",
    "            u = AnnoyIndex(f, 'euclidean')\n",
    "            u.load(ann_filename)\n",
    "        keys = pickle.load(open(keys_filename, 'rb'))\n",
    "        print('keys:', len(keys), keys[:5])\n",
    "        return u, keys\n",
    "    \n",
    "    start = time.time()\n",
    "    keys = []\n",
    "    embs = []\n",
    "    key=0\n",
    "    f = 768\n",
    "    u = AnnoyIndex(f, 'euclidean')\n",
    "    base_sub_dirs = os.listdir(base_dir)\n",
    "    for sub_dir in tqdm.tqdm(base_sub_dirs):\n",
    "        sub_dir = os.path.join(base_dir, sub_dir)\n",
    "        filenames = os.listdir(sub_dir)\n",
    "        for filename in filenames:\n",
    "            if not filename.endswith('.jpg') and not filename.endswith('.png'):\n",
    "#                 print(os.path.join(sub_dir, filename))\n",
    "                continue\n",
    "            filename = os.path.join(sub_dir, filename)\n",
    "#             key = filename\n",
    "            try:\n",
    "                img = cv2.imread(filename)\n",
    "                emb=seq_net.predict(img)\n",
    "                if f is None:\n",
    "                    print('shape:', emb.shape)\n",
    "                    if len(emb.shape) > 1 and emb.shape[1] != 1:\n",
    "                        return None, None\n",
    "                    f = emb.shape[0]\n",
    "                u.add_item(key, emb)\n",
    "                key+=1\n",
    "            except Exception as e:\n",
    "                print(filename, e)\n",
    "                continue\n",
    "            keys.append(filename)\n",
    "#             embs.append(emb)\n",
    "    end = time.time()\n",
    "    print('get_embedding time:', (end-start)/len(keys), len(keys))\n",
    "    \n",
    "#     f = 768  # 512/2048\n",
    "#     u = AnnoyIndex(f, 'euclidean')  # Length of item vector that will be indexed\n",
    "#     for key, value in tqdm.tqdm(enumerate(embs)):\n",
    "#         u.add_item(key, value)\n",
    "    u.build(100) # 100 trees\n",
    "    u.save(ann_filename)\n",
    "    pickle.dump(keys, open(keys_filename, 'wb'))\n",
    "    \n",
    "    return u, keys\n",
    "\n",
    "def evaluate_mae(u, keys, model_name, seq_net):\n",
    "    # ps = ['YongKang_img0.jpg', 'YongKang_img1.jpg', 'YongKang_img3.jpg', 'YongKang_img4.jpg']\n",
    "    query_sub_dirs = os.listdir(query_dir)\n",
    "    ps = []\n",
    "    for query_sub_dir in query_sub_dirs:\n",
    "        query_sub_dir = os.path.join(query_dir, query_sub_dir)\n",
    "        sub_ps = os.listdir(query_sub_dir)\n",
    "        for sub_p in sub_ps:\n",
    "            if sub_p.endswith('jpg') or sub_p.endswith('png'):\n",
    "                ps.append(os.path.join(query_sub_dir, sub_p))\n",
    "    filenames = []\n",
    "    min_sims = []\n",
    "    min_sim_filenames = []\n",
    "    sift_sims = []\n",
    "    for p in tqdm.tqdm(ps):\n",
    "        try:\n",
    "            img = cv2.imread(filename)\n",
    "            emb=seq_net.predict(img)\n",
    "        except Exception as e:\n",
    "            print(p, e)\n",
    "            continue\n",
    "#         print(p)\n",
    "        comparisons = u.get_nns_by_vector(target_feature, K)\n",
    "        min_sim = 1\n",
    "        min_sim_filename = ''\n",
    "        for i, comparison in enumerate(comparisons):\n",
    "            if p != keys[comparison]:\n",
    "                min_sim_filename = keys[comparison]\n",
    "        sift_sim = 0\n",
    "        filenames.append(p)\n",
    "        min_sims.append(min_sim)\n",
    "        min_sim_filenames.append(min_sim_filename)\n",
    "        sift_sims.append(sift_sim)\n",
    "        \n",
    "    result = pd.DataFrame({'filename': filenames, 'min_sim_filename': min_sim_filenames, 'min_sim': min_sims, 'sift_sim': sift_sims})\n",
    "    result.to_excel('result_'+model_name+'.xlsx')\n",
    "    \n",
    "    result_eval = result\n",
    "    result_eval['label'] = result_eval['filename'].str.split('/', expand=True)[5]  # TODO may change\n",
    "    result_eval['pred'] = result_eval['min_sim_filename'].str.split('/', expand=True)[5]  # TODO may change\n",
    "    result_eval['correct'] = result_eval['label'] == result_eval['pred']\n",
    "    result_eval.to_excel('result_eval_'+model_name+'.xlsx')\n",
    "    \n",
    "    return result_eval['correct'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f8b41",
   "metadata": {},
   "source": [
    "# 加载endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e81772",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=PyTorchPredictor(\n",
    "    endpoint_name='pytorch-inference-2022-03-18-06-53-11-274',\n",
    ")\n",
    "model=predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01e081d",
   "metadata": {},
   "source": [
    "# 生成随机投影森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510fa73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'data/haitian/haitian_recognition/644_final/images'\n",
    "query_dir = 'data/haitian/haitian_recognition/644_final/images'\n",
    "\n",
    "print('Model loaded.')\n",
    "u, keys=get_index_mae('mae_vit_base_pretrain', model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc338d9",
   "metadata": {},
   "source": [
    "# 推理+搜索结果+评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b089963",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='mae_vit_base_pretrain'\n",
    "K = 2  # 3/6/20/40\n",
    "base_dir = 'data/haitian/haitian_recognition/644_final/images'\n",
    "query_dir = 'data/haitian/haitian_recognition/644_final/images'\n",
    "\n",
    "\n",
    "u, keys=get_index_mae(model_name, model)\n",
    "correct_sum = evaluate_mae(u, keys, model_name, model)\n",
    "print('correct_sum:', correct_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p37",
   "language": "python",
   "name": "conda_pytorch_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
